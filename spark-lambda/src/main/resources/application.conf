clickstream {
  records = 200
  time_multiplier = 480
  pages = 15
  visitors = 1000000
  number_of_files = 50
  file_path = "E:\\VagrantBoxes\\spark-kafka-cassandra-applying-lambda-architecture\\vagrant\\data.tsv"
  dest_path = "E:\\VagrantBoxes\\spark-kafka-cassandra-applying-lambda-architecture\\vagrant\\input\\"
  topic = "weblogs-text"
  bootstrap_servers_config = "localhost:9092"

}
batchJob {
  is_debug = true
  spark_app_name = "Lambda with Spark"
  batch_duration_in_seconds = 4
  spark_client {
    zookeeper_connect = "localhost:2181"
    group_id = "lambda"
  }
  debug {
    hadoop_home_dir = "E:\\Scala\\WinUtils\\hadoop-common-2.2.0-bin-master"
    checkpoint_directory = "file:///E:/Scala/Temp"
    spark_master = "local[*]"
    file_path = "E:\\VagrantBoxes\\spark-kafka-cassandra-applying-lambda-architecture\\vagrant\\data.tsv"
  }
  release {
    checkpointDirectory = "hdfs://lambda-pluralsight:9000/spark/checkpoint"
    file_path = "file:///vagrant/data.tsv"
    dest_path = "file:///vagrant/input"
  }
}